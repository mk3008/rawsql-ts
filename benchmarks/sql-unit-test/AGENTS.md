## Benchmark policy (important)

Benchmark reports under `benchmarks/` are **pure artifacts generated by executable scripts**.
They are not hand-written documents and must never be edited directly.

### Rules

- Benchmark reports (e.g. `benchmarks/**/report.md`) are always the **result of running a script**.
- If a benchmark report is unclear, misleading, incomplete, or incorrect:
  **the benchmark script itself must be fixed**, not the report.
- Do not “patch” benchmark results by editing Markdown text, tables, or explanations by hand.
- Any change to benchmark interpretation must be expressed as:
  - a change in measured scope,
  - a change in benchmark parameters,
  - or a change in how measurements are collected and reported by the script.

### Vitest execution as the measurement target (important)

- The purpose of benchmarks in this repository is to measure **Vitest unit test execution performance**.
- Benchmarks must therefore **execute the same test code paths as the Vitest test suites**.
- Repository methods, fixtures, and testkit setup must be invoked through the **actual test classes or test scenarios**.

**Do not**:
- Reimplement repository calls manually for benchmarking purposes.
- Write standalone “benchmark-only” verification logic.
- Bypass existing test files and recreate assertions or setup logic by hand.

If a benchmark does not execute the same logic that Vitest runs,
it is **not measuring test performance** and is considered invalid.

### Test code as the source of truth

- Benchmarks must execute the **same code paths as the actual unit tests**.
- Repositories, fixtures, and testkit usage must be shared with the corresponding Vitest tests.
- Writing standalone or “theoretical” benchmark logic that ignores existing tests defeats the purpose and is not allowed.

Rationale:

Benchmarks exist to answer the question:

> “How fast are our real unit tests?”

If the benchmark does not measure the same code that tests execute,
the benchmark is invalid regardless of how polished the report looks.

Therefore:
**benchmark correctness is enforced at the script level, not at the report level.**
