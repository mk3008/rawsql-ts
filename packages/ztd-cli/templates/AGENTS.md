# Appendix: Development Workflow Using Zero Table Dependency (ZTD)

This application uses **Zero Table Dependency (ZTD)** as an internal development workflow for writing, testing, and maintaining SQL logic.  
ZTD is not part of the application's runtime behavior; rather, it provides a framework for:

- Maintaining consistent SQL across the project  
- Keeping schema, domain specifications, and enums synchronized  
- Ensuring deterministic SQL unit tests  
- Enabling structured collaboration between humans and AI  

This section documents how ZTD is used *inside this repository* as a development methodology.

---

## Generated files (important)

- `tests/generated/` is auto-generated and must never be committed.
- After cloning the repository (or in a clean environment), run `npx ztd ztd-config`.
- If TypeScript reports missing modules or type errors because `tests/generated/` is missing, run `npx ztd ztd-config`.

## ZTD Implementation Guide (src/)

The `src/` directory should contain pure TypeScript logic that operates on the row interfaces generated by `tests/generated/ztd-row-map.generated.ts`. Tests should import the row map, repositories should import DTOs, and fixtures must stay under `tests/`. Keep production code decoupled from the generated row map to preserve the distinction between implementation and test scaffolding.

### Repository SQL and DTO policy (important)

- Repository SQL must return application-facing DTO shapes.
- SQL SELECT statements should alias columns to camelCase and match the repository return types.
- Do not introduce intermediate `*Row` types when SQL already returns DTO-compatible shapes.
- Define separate Row types only when SQL intentionally returns database-shaped (snake_case) rows, and always convert them explicitly.

### Sequence / identity column policy (important)

- Sequence / identity columns (auto-generated IDs) are infrastructure concerns.
- Do **not** explicitly assign values to sequence / identity columns in `INSERT` statements unless explicitly instructed.
- Repository method inputs should omit sequence / identity columns by default.
- Only treat an ID as input data when it represents a business rule (e.g. natural keys, externally assigned IDs).

### No test-driven fallbacks in production code (important)

- **Do not add fallbacks in `src/` that exist only to accommodate ZTD/testkit/rewriter limitations.**
- If a query fails to be rewritten into ZTD form (e.g. rawsql-ts parsing/rewrite failure), **do not “paper over” it** by changing runtime behavior, adding `max(id)+1`, or introducing alternative logic paths.
- Instead, stop and report the issue with evidence:
  - The exact SQL that fails
  - The error message / symptoms
  - A minimal reproduction (smallest query that triggers the failure)
  - The expected behavior (what ZTD/testkit should have produced)

Rationale: Production code must not diverge from the intended SQL semantics due to tooling constraints. Tooling issues should be fixed in the tooling layer (rawsql-ts / ztd / testkit), not by altering runtime logic.

---

## ZTD Test Guide (tests/)

Fixtures come from the `ztd/ddl/` definitions and power `pg-testkit`. Always import table types from `tests/generated/ztd-row-map.generated.ts` when constructing scenarios, and rerun `npx ztd ztd-config` whenever schema changes to keep the fixtures and row map synchronized.

If you are working inside this repository's `ztd-playground`, regenerate the generated artifacts with `pnpm --filter ztd-playground exec ztd ztd-config`.

- Set `ZTD_EXECUTION_MODE=traditional` or pass `{ mode: 'traditional', traditional: { isolation: 'schema', cleanup: 'drop_schema' } }` to `createTestkitClient()` when you must exercise real Postgres semantics (locks, isolation, constraints). Traditional mode still runs the DDL inside `ztd/ddl/`, seeds the fixtures, executes any optional `setupSql`, and honors the configured `cleanup` strategy (`drop_schema` by default, `custom_sql`, or `none` for debugging) so the environment stays tidy. Use `isolation: 'none'` when your queries explicitly reference an existing schema and you cannot rely on schema-based isolation.


### ID expectations in tests (important)

- Do not assert auto-generated ID values (sequence / identity), such as "the next id is 11".
- When creating rows, assert only that an ID exists and has the correct type, or that it differs from known existing IDs.
- Only assert specific ID values when the ID is part of a business rule (not infrastructure), e.g. a natural key or a fixed, meaningful identifier.

## Parallel test policy (important)

- ZTD tests should be safe to run in parallel against a single Postgres instance because pg-testkit rewrites CRUD into fixture-backed SELECT queries (no physical schema changes).
- Do not start multiple Postgres instances per test file/worker, and do not isolate tests by creating per-test databases or schemas. This is unnecessary for ZTD and adds failure modes.
- Prefer one shared Postgres instance + multiple connections, limited only by your DB resources.

---

# ZTD Directory Layout

```
/ztd
  /ddl
    *.sql               <- physical schema definitions

  /domain-specs
    *.md                <- one behavioral SELECT per file (one SQL block)

  /enums
    *.md                <- one enum definition per file (one SQL block)

  README.md             <- documentation for the layout
  AGENTS.md             <- combined guidance for DDL, enums, and specs

/src                    <- application & repository logic
/tests                  <- ZTD tests, fixtures, row-maps
```

The file `tests/generated/ztd-layout.generated.ts` ensures ZTD CLI always points to the correct directories.

---

# Principles of ZTD in This Repository

### 1. Humans own the **definitions**
- Physical schema (DDL)
- Domain semantics (domain-specs)
- Enumerations (enums)
- Repository interfaces

### 2. AI assists with **implementation**
- Generating repository SQL
- Updating fixtures
- Producing intermediate TypeScript structures
- Ensuring SQL adheres to DDL, enums, and domain-specs

### 3. ZTD enforces **consistency**
ZTD tests verify that:
- SQL logic matches DDL shapes  
- SQL semantics match domain-specs  
- SQL values match enumerations  

If anything diverges, ZTD failures surface immediately and deterministically.

---

# Development Workflows

Different types of changes start from different entry points. Use the workflow appropriate for your situation.

---

# Workflow A — Starting From *DDL Changes*
Modifying tables, columns, constraints, indexes.

1. Edit DDL files in `ztd/ddl/`.
2. Run:

   ```bash
   npx ztd ztd-config
   ```

   This regenerates `tests/generated/ztd-row-map.generated.ts` from the updated schema.

3. Update repository SQL to match the new schema.
4. Update fixtures if result shapes changed.
5. Run tests.

**Flow:** DDL -> Repository SQL -> Fixtures/Tests -> Application

---

# Workflow B — Starting From *Repository Interface Changes*
Changing method signatures, adding new repository methods, etc.

1. Modify the repository interface or implementation in `/src`.
2. Use AI assistance to generate or update the SQL implementation.
3. If the generated SQL conflicts with domain-specs or enums, update definitions first.
4. Run ZTD tests.
5. Regenerate config if SQL output shape changed.

**Flow:** Interface -> SQL -> Specs (if needed) -> Tests

---

# Workflow C — Starting From *Repository SQL Logic Changes*
Bug fixes, refactoring, rewriting queries.

1. Edit SQL inside the repository.
2. Run ZTD tests.
3. If intended behavior changes, update the appropriate file in `ztd/domain-specs/`.
4. Update fixtures as needed.
5. Regenerate config if result shape changed.

**Flow:** SQL -> Domain-specs -> Tests

---

# Workflow D — Starting From *Enum or Domain Specification Changes*
Business rule changes or conceptual model updates.

## Editing enums:

1. Update the relevant `.md` file under `ztd/enums/`.
2. Run:

   ```bash
   npx ztd ztd-config
   ```

3. Update repository SQL referencing enum values.
4. Update fixtures/tests.

## Editing domain-specs:

1. Update the relevant `.md` file under `ztd/domain-specs/`.
2. Update repository SQL to reflect the new semantics.
3. Update or add tests.
4. Update DDL only if the new rules require schema changes.

**Flow:** Specs/Enums -> SQL -> Tests -> (DDL if required)

---

# Combined Real-World Examples

- Adding a new contract state:  
  enums -> domain-spec -> SQL -> config -> tests

- Adding a new table:  
  DDL -> config -> SQL -> fixtures -> tests

- Fixing business logic:  
  SQL -> domain-spec -> tests

ZTD ensures the development always converges into a consistent, validated workflow.

---

# Human Responsibilities

Humans maintain:

- Schema definitions (`ztd/ddl`)
- Domain logic definitions (`ztd/domain-specs`)
- Domain enumerations (`ztd/enums`)
- Repository interfaces and architectural decisions
- Acceptance/review of AI-generated patches

Humans decide **what is correct**.

---

# AI Responsibilities

AI must:

- Use domain-specs as the semantic source of truth  
- Use enums as the canonical vocabulary source  
- Use DDL as the physical structure constraint  
- Generate SQL consistent with all definitions  
- Update fixtures when needed  
- Never modify `ztd/AGENTS.md` or `ztd/README.md` without explicit instruction  

AI decides **how to implement**, but not **what is correct**.

---

# ZTD CLI Responsibilities

ZTD CLI:

- Parses DDL to compute schema shapes  
- Rewrites SQL via CTE shadowing for testing  
- Generates `ztd-row-map.generated.ts`  
- Enables deterministic, parallel SQL unit tests  

ZTD is the verification engine that validates correctness beyond static typing.

---

# Summary

This appendix documents how ZTD is used strictly as an **internal implementation and maintenance guide**.  
It does not affect the runtime behavior of the application.  
Its purpose is ensuring:

- Schema integrity  
- SQL correctness  
- Domain consistency  
- Reliable AI-assisted development  

With ZTD, **humans define the meaning**, **AI writes the implementation**, and **tests guarantee correctness**.
